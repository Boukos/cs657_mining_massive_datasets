{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir(os.curdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import mllib\n",
    "from pyspark.mllib.evaluation import RegressionMetrics\n",
    "from pyspark.mllib.feature import HashingTF, IDF\n",
    "from pyspark.mllib.feature import Word2Vec\n",
    "from pyspark.mllib.feature import StandardScalerModel\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.linalg.distributed import RowMatrix\n",
    "\n",
    "import numpy as np\n",
    "import os, csv, sys, time\n",
    "from random import randint\n",
    "from itertools import izip, izip_longest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shane\\programming\\cs657_mining_massive_datasets\\craigslist_clustering\\data\\cl_tiny.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def get_input(fn):\n",
    "\n",
    "fn = \"cl_tiny.csv\"\n",
    "cur_dir = os.path.abspath(os.curdir)\n",
    "input_file_path = os.path.normpath(os.path.join(cur_dir, \"..\", \"data\", fn))\n",
    "print(input_file_path)\n",
    "\n",
    "os.path.isfile(input_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# [(postTitle, postingURL, postLocation, time, lat, long, address, dateRetrieved, post_date, ad), ...]\n",
    "raw_ads = sc.textFile(input_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set = input.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# [ad0, ad1, ..]\n",
    "ads_rdd = raw_ads.map(lambda x: str(x.decode('utf-8', 'ignore')))\n",
    "# processed_rdd = input.map(lambda x: str(x.decode('utf-8', 'ignore'))).map(lambda x: x.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"Daziran Massage TherapyCall to make appointment.1314 Westgate Parkway, Suite 4 Dothan, AlabamaWe specialize in Back Walking, Deep Tissue, Sport Massage...etc$60/hour $65/hour deep tissue, we also have 90 Mins and 2 hours session.out call only within Dothan area.Open Monday to Saturday, 10am - 9pm, Sunday 1pm - 8pmshow contact infoAll major credit cards accepted    \"',\n",
       " '\"331 SPAWelcome to best asian massage. shiatsu and swedish, walk on your back , firm or relaxing massage.Great table shower.Our place is very clean and very comfortable.Every therapists are licensed and very professional and friendly.You\\'ll be a New person,In callHalf Hr: $60.00 with table showerOne Hr: $80.00 with table showerwe do accept credit cardsopen 9 am to 10 pm , 7days a weekTel:  show contact info*from panama city or beach: one mile before to I-10 on highway 331 to your left* from Tallahassee: Left turn to highway 331 (Exit 85) , we are 1 mile from I-10 on your right side building.*I-10 from alabama(Mobil) or Pesacola Fl - right turn to highway 331 and 1mile to your right.    \"']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_rdd.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_tfidf(rdd):\n",
    "    # While applying HashingTF only needs a single pass to the data, applying IDF needs two passes:\n",
    "    # First to compute the IDF vector and second to scale the term frequencies by IDF.\n",
    "    hashingTF = HashingTF()\n",
    "    tf = hashingTF.transform(rdd)\n",
    "    tf.cache()\n",
    "    idf = IDF().fit(tf)\n",
    "    tfidf = idf.transform(tf)\n",
    "    # spark.mllib's IDF implementation provides an option for ignoring terms\n",
    "    # which occur in less than a minimum number of documents.\n",
    "    # In such cases, the IDF for these terms is set to 0.\n",
    "    # This feature can be used by passing the minDocFreq value to the IDF constructor.\n",
    "    idfIgnore = IDF(minDocFreq=1).fit(tf)\n",
    "    tfidf_rdd = idfIgnore.transform(tf)\n",
    "    # list of SparseVectors [(doc_id_i: {word_id_j: tfidfscore_j, ...}), ... }]\n",
    "    return tfidf_rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SparseVector(1048576, {30136: 1.3228, 60275: 2.5813, 71269: 1.7209, 115245: 2.4006, 134386: 3.872, 145380: 5.5929, 156374: 1.6308, 189356: 1.3228, 208501: 4.0871, 219495: 0.2151, 263471: 2.0577, 274465: 0.0, 282612: 1.936, 293606: 0.8604, 337582: 3.6491, 356727: 0.3429, 367721: 1.936, 411697: 1.0288, 422691: 0.6859, 430838: 0.8604, 441832: 3.2267, 463820: 1.194, 485808: 1.3718, 515947: 1.4881, 559923: 0.6008, 570917: 2.0722, 579064: 1.2907, 590058: 1.0237, 612046: 0.7259, 623040: 0.6859, 634034: 0.2985, 653179: 2.9762, 664173: 2.3662, 686161: 0.4895, 697155: 0.9491, 708149: 2.0722, 738284: 1.7209, 771266: 0.3895, 782260: 0.6008, 812399: 3.6569, 845381: 2.9037, 856375: 1.2015, 886510: 3.872, 897504: 7.744, 908498: 1.3718, 960625: 2.5813, 971619: 0.3895, 982613: 1.2015, 1004601: 0.7259, 1045730: 2.1511}),\n",
       " SparseVector(1048576, {19142: 1.1314, 30136: 0.6614, 60275: 8.3893, 71269: 3.0116, 93257: 1.6308, 104251: 2.7181, 115245: 1.7147, 134386: 5.808, 145380: 11.4009, 156374: 0.5436, 167368: 2.4031, 189356: 2.6456, 208501: 6.6685, 219495: 2.7964, 263471: 3.0865, 274465: 0.0, 282612: 2.1511, 293606: 2.1511, 304600: 1.0361, 356727: 1.3718, 367721: 4.3022, 389709: 0.9491, 411697: 3.4294, 422691: 0.6859, 430838: 3.2267, 441832: 6.2382, 463820: 0.2985, 485808: 3.4294, 504953: 1.0872, 537935: 0.869, 570917: 2.0722, 579064: 3.0116, 590058: 0.7678, 612046: 1.4519, 623040: 0.3429, 634034: 2.3879, 664173: 6.2382, 686161: 0.9791, 738284: 3.4418, 782260: 0.6008, 793254: 0.6008, 812399: 5.3778, 856375: 0.6008, 867369: 2.7091, 886510: 8.6045, 897504: 10.9707, 908498: 0.3429, 919492: 2.7091, 930486: 0.4383, 941480: 2.7091, 960625: 1.7209, 971619: 4.6736, 982613: 1.2015, 993607: 0.7949, 1004601: 1.4519, 1015595: 5.4736, 1045730: 3.4418})]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfIgnore.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#     sentence = \"aa bb ab\" * 10 + \"a cd \" * 10\n",
    "#     localDoc = [sentence, sentence]\n",
    "#     doc = sc.parallelize(localDoc).map(lambda line: line.split(\" \"))\n",
    "#     model = Word2Vec().setVectorSize(10).setSeed(42).fit(doc)\n",
    "# i think it is expecting a list of document lists [[word1, word2,...], ...]\n",
    "def get_word2vec(rdd):\n",
    "    word2vec = Word2Vec()\n",
    "    model = word2vec.fit(ads_rdd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# distributed matrix\n",
    "matrix_rdd = RowMatrix(tfidf_rdd)\n",
    "svd = matrix_rdd.computeSVD(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseMatrix(1048576, 2, [-0.0, -0.0, 0.0, 0.0, -0.0, 0.0, -0.0, 0.0, ..., -0.0, 0.0, -0.0, -0.0, 0.0, 0.0, -0.0, 0.0], 0)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
